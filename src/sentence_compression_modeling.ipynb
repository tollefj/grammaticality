{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What word describes feeling sorrow regret or remorse for something?',\n",
       "  'The word meaning sorrow remorse or regret?'),\n",
       " ('The word meaning sorrow remorse or regret?', 'What means full of feeling?'),\n",
       " ('What word describes feeling sorrow regret or remorse for something?',\n",
       "  'What means full of feeling?'),\n",
       " ('What kinds of animals does live in namib desert inafrica?',\n",
       "  'What kindes of animals live in the desert?'),\n",
       " ('What kindes of animals live in the desert?',\n",
       "  'What kind animals live deserts?')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "\n",
    "filename = \"wikianswers_3length-100000samples.jsonl\"\n",
    "filepath = \"data/\" + filename\n",
    "\n",
    "# load the jsonline as \"pairs\":\n",
    "with jsonlines.open(filepath) as reader:\n",
    "    # read the pairs as tuples of sentences \n",
    "    pairs = [tuple(p[\"set\"]) for p in reader]\n",
    "pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296941"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just select a subset of 1000 pairs to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect stats of the data, such as max sentence length:\n",
    "max_sentence_length = max([len(s.split()) for p in pairs for s in p])\n",
    "max_sentence_length\n",
    "# remove all pairs with any sentence longer than 30 words\n",
    "pairs = [p for p in pairs if max([len(s.split()) for s in p]) <= 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now inspect max sequence length (i.e. characters)\n",
    "max_sequence_length = max([len(s) for p in pairs for s in p])\n",
    "max_sequence_length\n",
    "\n",
    "# discard all examples with sentences longer than 200 characters\n",
    "pairs = [p for p in pairs if max([len(s) for s in p]) <= 200]\n",
    "len(pairs)\n",
    "\n",
    "test_pairs = pairs[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How many quarts of oil does a 4-cylinder honda civic del sol take?',\n",
       "  'How many quarts of oil in honda del sol?'),\n",
       " ('How many quarts of oil in honda del sol?', 'Oil del sol 95?'),\n",
       " ('Does chugging beer make you more drunk then shots?',\n",
       "  'How do you chug alcohol fast?'),\n",
       " ('Does chugging beer make you more drunk then shots?',\n",
       "  'How do you chug beer?'),\n",
       " ('How do you chug alcohol fast?', 'How do you chug beer?'),\n",
       " ('What happens to the nipples in puberty for boys?',\n",
       "  'Do boys nipples hurt during puberty?'),\n",
       " ('Does your nipple enlarge or becomes painful during pubert boys?',\n",
       "  'Do boys nipples hurt during puberty?'),\n",
       " ('Does your nipple enlarge or becomes painful during pubert boys?',\n",
       "  'What happens to the nipples in puberty for boys?'),\n",
       " ('What time do lawyers get up for work?', 'What time does a lawyer get up?'),\n",
       " ('What time does a lawyer get up?', 'What time do lawyers wake up?')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a subset:\n",
    "pairs = pairs[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/tollefj/git/grammaticality/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 1.76MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 3.57MB/s]\n",
      "/lhome/tollefj/git/grammaticality/venv/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Downloading pytorch_model.bin: 100%|██████████| 892M/892M [00:09<00:00, 93.9MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 885kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressionDataset(Dataset):\n",
    "    def __init__(self, sentence_pairs):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentence_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.sentence_pairs[idx]\n",
    "        source_sentence = pair[0]\n",
    "        target_sentence = pair[1]\n",
    "\n",
    "        source_tokenized = tokenizer.encode_plus(source_sentence, max_length=200, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        target_tokenized = tokenizer.encode_plus(target_sentence, max_length=200, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "        source_ids = source_tokenized['input_ids'].squeeze()\n",
    "        source_mask = source_tokenized['attention_mask'].squeeze()\n",
    "        target_ids = target_tokenized['input_ids'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids,\n",
    "            'source_mask': source_mask,\n",
    "            'target_ids': target_ids\n",
    "        }\n",
    "\n",
    "# Assume `pairs` is a list of your sentence pairs\n",
    "dataset = CompressionDataset(pairs)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.1688132027075404\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.10802048314658422\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.09349556255435186\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.08177530191957004\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.07145963946268671\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.06317383943805618\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:31<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.05618708687169211\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.048770262726715634\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.0433187090924808\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.03848822326177642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        source_ids = batch['source_ids'].to(device)\n",
    "        source_mask = batch['source_mask'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=source_ids, attention_mask=source_mask, labels=target_ids)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {epoch_loss/len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How many quarts of oil does a 4-cylinder honda civic del sol take?',\n",
       "  'How many quarts of oil in honda del sol?'),\n",
       " ('How many quarts of oil in honda del sol?', 'Oil del sol 95?'),\n",
       " ('Does chugging beer make you more drunk then shots?',\n",
       "  'How do you chug alcohol fast?'),\n",
       " ('Does chugging beer make you more drunk then shots?',\n",
       "  'How do you chug beer?'),\n",
       " ('How do you chug alcohol fast?', 'How do you chug beer?'),\n",
       " ('What happens to the nipples in puberty for boys?',\n",
       "  'Do boys nipples hurt during puberty?'),\n",
       " ('Does your nipple enlarge or becomes painful during pubert boys?',\n",
       "  'Do boys nipples hurt during puberty?'),\n",
       " ('Does your nipple enlarge or becomes painful during pubert boys?',\n",
       "  'What happens to the nipples in puberty for boys?'),\n",
       " ('What time do lawyers get up for work?', 'What time does a lawyer get up?'),\n",
       " ('What time does a lawyer get up?', 'What time do lawyers wake up?')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold:  Is a chimpanzee endangered and why is it endangered?\n",
      "Shorter:  Have chimpanzees been endangered?\n",
      "Compressed Sentence:  Is a chimpanzee\n",
      "\n",
      "Gold:  What is the locations possible economic impact on Cuba's population?\n",
      "Shorter:  What is the population number of Cuba?\n",
      "Compressed Sentence:  What is the population density of Cuba?\n",
      "\n",
      "Gold:  Which state is started commonwealth games?\n",
      "Shorter:  Who started the commonwealth games?\n",
      "Compressed Sentence:  Who started commonwealth game?\n",
      "\n",
      "Gold:  Some thing can hurt mor than a belly flop an you prformns acrobatics high above sea world water?\n",
      "Shorter:  Is a high water table a good thing or a bad thing?\n",
      "Compressed Sentence:  How do you get high above sea world?\n",
      "\n",
      "Gold:  Is there such thing as a proffesional pimple popper?\n",
      "Shorter:  Best thing for pimples when your in year 6?\n",
      "Compressed Sentence:  Is there such thing as a pi\n",
      "\n",
      "Gold:  Which of these factors influences one is sense of sense of self?\n",
      "Shorter:  Which of these factors influences one is sense of sense of self?\n",
      "Compressed Sentence:  What factors influences one sense of self?\n",
      "\n",
      "Gold:  Who kills fred weasley in the last harry potter book?\n",
      "Shorter:  Who killed fred weasley in HP 7?\n",
      "Compressed Sentence:  Who killed fred weasley in\n",
      "\n",
      "Gold:  151 The reason why flowers have colors and fragrance is to attract pollinator such as bees and birds?\n",
      "Shorter:  How do plants get pollinators?\n",
      "Compressed Sentence:  What attracts pollinators?\n",
      "\n",
      "Gold:  How much is the value of a US of america one dollar coin worth?\n",
      "Shorter:  1 dollar coin?\n",
      "Compressed Sentence:  Value 1 dollar coin?\n",
      "\n",
      "Gold:  Which layer of the earth contains a layer of hot molten rock?\n",
      "Shorter:  What layer is molten?\n",
      "Compressed Sentence:  What layer is molten?\n",
      "\n",
      "Gold:  The role of finance in economuc society?\n",
      "Shorter:  Where was Finance Born?\n",
      "Compressed Sentence:  What role does finance play in econom\n",
      "\n",
      "Gold:  Why didnt you get a jet pack grand theft auto liberty city stories for psp when you used the cheat L1 R1 left right tiangle circle?\n",
      "Shorter:  What is the cheat of a jet pack in liberty city stories at psp?\n",
      "Compressed Sentence:  What is cheat for psp in\n",
      "\n",
      "Gold:  What are the male reproductive organ of a flower consists of an anther and a filament?\n",
      "Shorter:  Prone organ in younger male called?\n",
      "Compressed Sentence:  What organ is the male reproductive organ?\n",
      "\n",
      "Gold:  Who are famous people from thailand?\n",
      "Shorter:  Famous people thailand?\n",
      "Compressed Sentence:  Famous people thailand?\n",
      "\n",
      "Gold:  After the ratification of the constitution who supported a strong central government that promoted the financial interest of merchants and business?\n",
      "Shorter:  Why did the north support a strong central government?\n",
      "Compressed Sentence:  Who supported strong government?\n",
      "\n",
      "Gold:  What explorer managed to swim ashore after a failed attempt to colonize north americas coastline?\n",
      "Shorter:  First Englishman to attempt a colony?\n",
      "Compressed Sentence:  First Englishman to attempt a colony\n",
      "\n",
      "Gold:  What is kentucky 's motto?\n",
      "Shorter:  What the kentucky motto?\n",
      "Compressed Sentence:  What is kentucky '\n",
      "\n",
      "Gold:  How many times have Zac Eforn and Vanessa Hudgens broke up?\n",
      "Shorter:  Does vanessa hudgens broke up with zac?\n",
      "Compressed Sentence:  Vanessa hudgens and za\n",
      "\n",
      "Gold:  What natural resources did humans compete for?\n",
      "Shorter:  What r human resources?\n",
      "Compressed Sentence:  What resources did humans compete for?\n",
      "\n",
      "Gold:  How long can a desert death adder live?\n",
      "Shorter:  Is a death adder a snake?\n",
      "Compressed Sentence:  How long can a death adder live\n",
      "\n",
      "Gold:  What are the odds of bowling a perfect game with 4 rollers?\n",
      "Shorter:  How do you get a perfect game in bowling?\n",
      "Compressed Sentence:  Odds of bowling a perfect\n",
      "\n",
      "Gold:  What is the locations possible economic impact on Cuba's population?\n",
      "Shorter:  What i cuba's population?\n",
      "Compressed Sentence:  What is the population density of Cuba?\n",
      "\n",
      "Gold:  Who is the Congressional representative for bay village ithe Ohio House of Representatives?\n",
      "Shorter:  How many seat are in ohio house of representatives?\n",
      "Compressed Sentence:  Who is ohios representatives\n",
      "\n",
      "Gold:  What kind of gasoline does a lawnmower use?\n",
      "Shorter:  What type oil lawnmowers?\n",
      "Compressed Sentence:  What kind of gasoline does a lawnm\n",
      "\n",
      "Gold:  How mutch money does Oboma make a year?\n",
      "Shorter:  How much does Obama get a year?\n",
      "Compressed Sentence:  How much does Obama get a year?\n",
      "\n",
      "Gold:  Acid rain is caused by and results in?\n",
      "Shorter:  How rain become acidic?\n",
      "Compressed Sentence:  How rain become acidic?\n",
      "\n",
      "Gold:  Is it true or false that senators are elected by the vote of all the people in their states?\n",
      "Shorter:  Who is elected by state vote?\n",
      "Compressed Sentence:  Who is elected by state vote?\n",
      "\n",
      "Gold:  When uniport is going do their post ume exam?\n",
      "Shorter:  When is uniport post ume?\n",
      "Compressed Sentence:  When is uniport post ume?\n",
      "\n",
      "Gold:  Era after civil war in which effort was made to rebuild and reintegrate the south?\n",
      "Shorter:  Rebuilding after the civil war was called?\n",
      "Compressed Sentence:  Rebuilding after the civil war was called?\n",
      "\n",
      "Gold:  What happens on a first offense shoplifting age sixteen?\n",
      "Shorter:  2nd offense of shoplifting?\n",
      "Compressed Sentence:  First offense of shoplifting?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compress_sentence(sentence):\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer.encode_plus(sentence, return_tensors=\"pt\", max_length=512, padding='max_length', truncation=True)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)\n",
    "\n",
    "    compressed_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Compressed Sentence: \", compressed_sentence)\n",
    "    return compressed_sentence\n",
    "\n",
    "\n",
    "# select 30 random samples from test_pairs\n",
    "import random\n",
    "random.seed(42)\n",
    "test_pairs = random.sample(test_pairs, 30)\n",
    "\n",
    "\n",
    "for gold, shorter in test_pairs:\n",
    "    print(\"Gold: \", gold)\n",
    "    print(\"Shorter: \", shorter)\n",
    "    compress_sentence(gold)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wl-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
