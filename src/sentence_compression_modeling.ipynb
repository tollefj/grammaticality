{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What word describes feeling sorrow regret or remorse for something?',\n",
       "  'The word meaning sorrow remorse or regret?'),\n",
       " ('The word meaning sorrow remorse or regret?', 'What means full of feeling?'),\n",
       " ('What word describes feeling sorrow regret or remorse for something?',\n",
       "  'What means full of feeling?'),\n",
       " ('What kinds of animals does live in namib desert inafrica?',\n",
       "  'What kindes of animals live in the desert?'),\n",
       " ('What kindes of animals live in the desert?',\n",
       "  'What kind animals live deserts?')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "\n",
    "filename = \"wikianswers_3length-100000samples.jsonl\"\n",
    "filepath = \"../../data/\" + filename\n",
    "\n",
    "# load the jsonline as \"pairs\":\n",
    "with jsonlines.open(filepath) as reader:\n",
    "    # read the pairs as tuples of sentences \n",
    "    pairs = [tuple(p[\"set\"]) for p in reader]\n",
    "pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296941"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just select a subset of 1000 pairs to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect stats of the data, such as max sentence length:\n",
    "max_sentence_length = max([len(s.split()) for p in pairs for s in p])\n",
    "max_sentence_length\n",
    "# remove all pairs with any sentence longer than 30 words\n",
    "pairs = [p for p in pairs if max([len(s.split()) for s in p]) <= 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293524"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now inspect max sequence length (i.e. characters)\n",
    "max_sequence_length = max([len(s) for p in pairs for s in p])\n",
    "max_sequence_length\n",
    "\n",
    "# discard all examples with sentences longer than 200 characters\n",
    "pairs = [p for p in pairs if max([len(s) for s in p]) <= 200]\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/wl-upgrade/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressionDataset(Dataset):\n",
    "    def __init__(self, sentence_pairs):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentence_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.sentence_pairs[idx]\n",
    "        source_sentence = pair[0]\n",
    "        target_sentence = pair[1]\n",
    "\n",
    "        source_tokenized = tokenizer.encode_plus(source_sentence, max_length=200, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        target_tokenized = tokenizer.encode_plus(target_sentence, max_length=200, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "        source_ids = source_tokenized['input_ids'].squeeze()\n",
    "        source_mask = source_tokenized['attention_mask'].squeeze()\n",
    "        target_ids = target_tokenized['input_ids'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids,\n",
    "            'source_mask': source_mask,\n",
    "            'target_ids': target_ids\n",
    "        }\n",
    "\n",
    "# Assume `pairs` is a list of your sentence pairs\n",
    "dataset = CompressionDataset(pairs)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8199895ac14a088592624c5e519439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.progress import track\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in track(range(epochs)):\n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        source_ids = batch['source_ids'].to(device)\n",
    "        source_mask = batch['source_mask'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=source_ids, attention_mask=source_mask, labels=target_ids)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {epoch_loss/len(dataloader)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wl-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
