{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow model trained from POS data:\n",
    "path = \"/Users/tollef/Downloads/git/PHD/SUMMARIZATION/grammaticality/src/POS-grammar-check/models/is_gram_20230512-141601_99acc.h5\"\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nocola ungrammatical data:\n",
    "path = \"/Users/tollef/Downloads/git/PHD/SUMMARIZATION/grammaticality/src/data/nocola_parsed/nocola_ungrammatical_dev.txt\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ungrammatical = f.readlines()\n",
    "ungrammatical = [line.split(\"\\t\")[0].strip() for line in ungrammatical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alt dette kan påvirke helsen og livskvaliteten i negativ rettning.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ungrammatical[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ungrammatical)\n",
    "ungrammatical = ungrammatical[:100]  # subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likevel tror jeg ikke at det bare er på grunn av den lette tilgangen at handelen på Internett er så populært.\n",
      "--> Grammatical (92% confidence)\n",
      "Alt dette kan påvirke helsen og livskvaliteten i negativ rettning.\n",
      "--> Grammatical (91% confidence)\n",
      "Her passer det kanskje godt å kort diskutere om eliteutøvere i dag selv er ansvarlige for det kompromissløse resultatjaget, eller omsterke sponsorer og bakmenn må ta sin del av skylden.\n",
      "--> Grammatical (91% confidence)\n",
      "\"Et smil er bruen til forståelse\", slik lyder en kinesisk visdom oversatt på norsk.\n",
      "--> Grammatical (92% confidence)\n",
      "Derfor er det enklere og på denne måten fortere enn kollektivtransport.\n",
      "--> Grammatical (35% confidence)\n",
      "M Det krever tid og tålmodighet, og de to tingene er det vanskelig å finne hos unge gutter.\n",
      "--> Grammatical (92% confidence)\n",
      "Man kan se at utviklingen i mitt hjemland, samt i hele den vestlige verden har ført fram til et mer likestilt samfunn.\n",
      "--> Grammatical (92% confidence)\n",
      "Jeg håper at jeg har et så godt vennskap som faren min, men det gjør jeg kanskje ikke.\n",
      "--> Ungrammatical (98% confidence)\n",
      "Jeg kan ikke vite alt sikkert om framtiden min men jeg vet at jeg skal være fornøyd i framtiden, og jeg glede r meg.\n",
      "--> Grammatical (92% confidence)\n",
      "Det er alltid koselig å komme ut av huset mitt for å handle litt.\n",
      "--> Grammatical (92% confidence)\n",
      "Jeg håper at han skal få vennene snart.\n",
      "--> Grammatical (90% confidence)\n",
      "For min del er det ikke så viktig om skal man bor i sentrum i en stor by eller i en drabantby eller på landet.\n",
      "--> Grammatical (92% confidence)\n",
      "Derfor trenger man å skarpe sine sanser, mener jeg.\n",
      "--> Grammatical (92% confidence)\n",
      "Å forstå naturen og alt som tilhører den, er en dyrebar gave vi har fått fra Gud, \"Vår herre\".\n",
      "--> Grammatical (91% confidence)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "index can't contain negative values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m pos \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mpos_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m sent]\n\u001b[1;32m     68\u001b[0m \u001b[39m# create 3 shuffled examples:\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msent\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m--> \u001b[39m\u001b[39m{\u001b[39;00mparse_pred(pred_from_pos(pos))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 34\u001b[0m, in \u001b[0;36mpred_from_pos\u001b[0;34m(pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpred_from_pos\u001b[39m(pos):\n\u001b[0;32m---> 34\u001b[0m     pos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mpad(pos, (\u001b[39m0\u001b[39;49m, MAX_LEN \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(pos)), constant_values\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mUNK\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m     pos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvectorize(pos_map\u001b[39m.\u001b[39mget)(pos)\n\u001b[1;32m     36\u001b[0m     pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39masarray([pos]), verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/numpy/lib/arraypad.py:744\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`pad_width` must be of integral type.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    743\u001b[0m \u001b[39m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m pad_width \u001b[39m=\u001b[39m _as_pairs(pad_width, array\u001b[39m.\u001b[39;49mndim, as_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(mode):\n\u001b[1;32m    747\u001b[0m     \u001b[39m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     function \u001b[39m=\u001b[39m mode\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/numpy/lib/arraypad.py:510\u001b[0m, in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    508\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mravel()  \u001b[39m# Ensure x[0], x[1] works\u001b[39;00m\n\u001b[1;32m    509\u001b[0m         \u001b[39mif\u001b[39;00m as_index \u001b[39mand\u001b[39;00m (x[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m x[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 510\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindex can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain negative values\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m         \u001b[39mreturn\u001b[39;00m ((x[\u001b[39m0\u001b[39m], x[\u001b[39m1\u001b[39m]),) \u001b[39m*\u001b[39m ndim\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m as_index \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mmin() \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: index can't contain negative values"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"nb_core_news_md\")\n",
    "\n",
    "s = \"Frakoblingen skjedde ikke, og raketten begynte å spinne. Den spant i omtrent ett minutt før det kom en eksplosjon som ødela begge deler av raketten.\"\n",
    "\n",
    "doc = nlp(s)\n",
    "\n",
    "MAX_LEN = 34\n",
    "pos_map = {\n",
    "    'ADJ': 0,\n",
    "    'ADP': 1,\n",
    "    'ADV': 2,\n",
    "    'AUX': 3,\n",
    "    'CCONJ': 4,\n",
    "    'DET': 5,\n",
    "    'INTJ': 6,\n",
    "    'NOUN': 7,\n",
    "    'NUM': 8,\n",
    "    'PART': 9,\n",
    "    'PRON': 10,\n",
    "    'PROPN': 11,\n",
    "    'PUNCT': 12,\n",
    "    'SCONJ': 13,\n",
    "    'SYM': 14,\n",
    "    'UNK': 15,\n",
    "    'VERB': 16,\n",
    "    'X': 17\n",
    "}\n",
    "\n",
    "def pred_from_pos(pos):\n",
    "    pos = np.pad(pos, (0, MAX_LEN - len(pos)), constant_values=\"UNK\")\n",
    "    pos = np.vectorize(pos_map.get)(pos)\n",
    "    pred = model.predict(np.asarray([pos]), verbose=0)[0][0]\n",
    "    return pred\n",
    "\n",
    "def pred_from_doc(doc):\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    return pred_from_pos(pos)\n",
    "\n",
    "def pred_from_text(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    return pred_from_doc(doc)\n",
    "\n",
    "\n",
    "def parse_pred(pred, threshold=0.08):\n",
    "    # badly worded sentences will typically have a score of 0.001 or similar.\n",
    "    res = \"Grammatical\" if pred > threshold else \"Ungrammatical\"\n",
    "    confidence = pred * 100 if pred > threshold else (1 - pred) * 100\n",
    "    return f\"{res} ({confidence:.0f}% confidence)\"\n",
    "\n",
    "def shuffle_spacy_doc(doc):\n",
    "    random_seed = 42\n",
    "    # shuffle on the text and pos tags equally\n",
    "    texts = [token.text for token in doc]\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    random.Random(random_seed).shuffle(texts)\n",
    "    random.Random(random_seed).shuffle(pos)\n",
    "    return texts, pos\n",
    "\n",
    "\n",
    "for text in ungrammatical:\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        pos = [token.pos_ for token in sent]\n",
    "        # create 3 shuffled examples:\n",
    "        print(f\"{sent}\\n--> {parse_pred(pred_from_pos(pos))}\")\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
